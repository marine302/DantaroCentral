#!/usr/bin/env python3
"""
ì‹¤ì œ ê±°ë˜ì†Œ ë°ì´í„° ìˆ˜ì§‘ ë° ëŒ€ì‹œë³´ë“œ ì—°ë™ ì„œë¹„ìŠ¤
OKX, Upbit, Coinone, Gate.io ì‹¤ì‹œê°„ API ì—°ë™
"""
import asyncio
import logging
import sys
import os
from datetime import datetime
from typing import Dict, List, Any

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'backend'))

from app.core.config import settings
from app.services.market_data_collector import market_data_collector
from app.api.v1.endpoints.websocket import connection_manager
from app.database.redis_cache import redis_manager

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/real_data_collection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class RealDataService:
    """ì‹¤ì œ ê±°ë˜ì†Œ ë°ì´í„° ìˆ˜ì§‘ ë° ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.running = False
        self.collection_interval = 30  # 30ì´ˆë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘
        self.stats = {
            'data_points_collected': 0,
            'broadcasts_sent': 0,
            'start_time': None,
            'last_collection': None,
            'active_exchanges': []
        }
        
    async def initialize_exchanges(self):
        """ê±°ë˜ì†Œ ì„¤ì • ë° ì´ˆê¸°í™”"""
        logger.info("ğŸ”§ ê±°ë˜ì†Œ API ì—°ê²° ì´ˆê¸°í™”...")
        
        exchange_configs = {}
        
        # OKX ì„¤ì • (ì‹¤ì œ API í‚¤ ì‚¬ìš©)
        if hasattr(settings, 'okx_api_key') and settings.okx_api_key:
            exchange_configs['okx'] = {
                'api_key': settings.okx_api_key,
                'secret_key': settings.okx_secret_key,
                'passphrase': getattr(settings, 'okx_passphrase', '')
            }
            logger.info("âœ… OKX API í‚¤ ì„¤ì • ì™„ë£Œ")
        
        # Upbit ì„¤ì • (ê³µê°œ API - API í‚¤ ë¶ˆí•„ìš”)
        try:
            # Upbitì€ ê³µê°œ APIë¡œ í…ŒìŠ¤íŠ¸
            exchange_configs['upbit'] = {
                'api_key': 'public_access',  # ê³µê°œ API
                'secret_key': 'public_access'
            }
            logger.info("âœ… Upbit ê³µê°œ API ì„¤ì • ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"Upbit ì„¤ì • ê±´ë„ˆë›°ê¸°: {e}")
        
        # Coinone ì„¤ì •
        if hasattr(settings, 'coinone_api_key') and settings.coinone_api_key:
            exchange_configs['coinone'] = {
                'api_key': settings.coinone_api_key,
                'secret_key': settings.coinone_secret_key
            }
            logger.info("âœ… Coinone API í‚¤ ì„¤ì • ì™„ë£Œ")
        
        # Gate.io ì„¤ì •
        if hasattr(settings, 'gate_api_key') and settings.gate_api_key:
            exchange_configs['gate'] = {
                'api_key': settings.gate_api_key,
                'secret_key': settings.gate_secret_key
            }
            logger.info("âœ… Gate.io API í‚¤ ì„¤ì • ì™„ë£Œ")
        
        if not exchange_configs:
            raise ValueError("âŒ ì„¤ì •ëœ ê±°ë˜ì†Œ APIê°€ ì—†ìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        
        # MarketDataCollector ì„¤ì •
        market_data_collector.configure_exchanges(exchange_configs)
        
        # ìˆ˜ì§‘í•  ì‹¬ë³¼ ì„¤ì • (ë‹¤ì¤‘ ê±°ë˜ì†Œ ì§€ì›)
        target_symbols = [
            'BTC-USDT', 'ETH-USDT', 'SOL-USDT', 'ADA-USDT', 'DOT-USDT',
            'MATIC-USDT', 'AVAX-USDT', 'ATOM-USDT', 'NEAR-USDT', 'FTM-USDT',
            'LTC-USDT', 'XRP-USDT', 'DOGE-USDT', 'LINK-USDT', 'UNI-USDT'
        ]
        market_data_collector.set_target_symbols(target_symbols)
        
        self.stats['active_exchanges'] = list(exchange_configs.keys())
        logger.info(f"ğŸ›ï¸ {len(exchange_configs)}ê°œ ê±°ë˜ì†Œ ì—°ê²° ì™„ë£Œ: {list(exchange_configs.keys())}")
        
    async def collect_and_broadcast_data(self):
        """ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ë° WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        try:
            logger.info("ğŸ“Š ì‹¤ì œ ì‹œì¥ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...")
            
            # ì‹¤ì œ ê±°ë˜ì†Œì—ì„œ ë°ì´í„° ìˆ˜ì§‘
            data_points = await market_data_collector.collect_all_data()
            
            if not data_points:
                logger.warning("âš ï¸ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            self.stats['data_points_collected'] += len(data_points)
            self.stats['last_collection'] = datetime.now()
            
            logger.info(f"âœ… {len(data_points)}ê°œ ì‹¤ì œ ë°ì´í„° í¬ì¸íŠ¸ ìˆ˜ì§‘ ì™„ë£Œ")
            
            # ë°ì´í„° í¬ë§· ë³€í™˜ ë° ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì¤€ë¹„
            await self.format_and_broadcast_data(data_points)
            
            # Redisì— ë°ì´í„° ì €ì¥
            await market_data_collector.process_and_store_data(data_points)
            
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ìˆ˜ì§‘/ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def format_and_broadcast_data(self, data_points):
        """ë°ì´í„° í¬ë§· ë³€í™˜ ë° WebSocket ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        if not connection_manager.active_connections:
            logger.info("ğŸ“¡ í™œì„±í™”ëœ WebSocket ì—°ê²°ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê°€ê²© ë°ì´í„° í¬ë§· (ëŒ€ì‹œë³´ë“œ í˜•ì‹ì— ë§ê²Œ)
        price_data = []
        arbitrage_data = []
        kimchi_data = []
        
        # ê±°ë˜ì†Œë³„, ì‹¬ë³¼ë³„ ë°ì´í„° ê·¸ë£¹í•‘
        exchange_prices = {}
        for point in data_points:
            if point.exchange not in exchange_prices:
                exchange_prices[point.exchange] = {}
            
            # ì‹¬ë³¼ ì´ë¦„ ì •ê·œí™” (BTC-USDT -> BTC)
            clean_symbol = point.symbol.split('-')[0].split('_')[0].upper()
            exchange_prices[point.exchange][clean_symbol] = {
                'price': point.price,
                'volume': point.volume_24h,
                'change_24h': point.change_24h,
                'timestamp': point.timestamp.isoformat()
            }
            
            # ê°€ê²© ë°ì´í„° ì¶”ê°€
            price_data.append({
                'exchange': point.exchange.title(),
                'symbol': clean_symbol,
                'price': round(point.price, 2),
                'volume': round(point.volume_24h, 2),
                'change_24h': round(point.change_24h, 2),
                'timestamp': point.timestamp.isoformat()
            })
        
        # ì°¨ìµê±°ë˜ ê¸°íšŒ ê³„ì‚°
        arbitrage_data = self.calculate_arbitrage_opportunities(exchange_prices)
        
        # ê¹€ì¹˜ í”„ë¦¬ë¯¸ì—„ ê³„ì‚°
        kimchi_data = self.calculate_kimchi_premiums(exchange_prices)
        
        # WebSocketìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        await self.broadcast_real_data(price_data, arbitrage_data, kimchi_data)
        
    def calculate_arbitrage_opportunities(self, exchange_prices: Dict) -> List[Dict]:
        """ì‹¤ì œ ê°€ê²© ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì°¨ìµê±°ë˜ ê¸°íšŒ ê³„ì‚°"""
        opportunities = []
        
        # ëª¨ë“  ì‹¬ë³¼ì— ëŒ€í•´ ê±°ë˜ì†Œ ê°„ ê°€ê²© ë¹„êµ
        all_symbols = set()
        for exchange_data in exchange_prices.values():
            all_symbols.update(exchange_data.keys())
        
        for symbol in all_symbols:
            symbol_prices = []
            
            # í•´ë‹¹ ì‹¬ë³¼ì„ ì§€ì›í•˜ëŠ” ê±°ë˜ì†Œë“¤ì˜ ê°€ê²© ìˆ˜ì§‘
            for exchange, prices in exchange_prices.items():
                if symbol in prices:
                    symbol_prices.append({
                        'exchange': exchange,
                        'price': prices[symbol]['price'],
                        'volume': prices[symbol]['volume']
                    })
            
            # ìµœì†Œ 2ê°œ ê±°ë˜ì†Œì—ì„œ í•´ë‹¹ ì‹¬ë³¼ì´ ê±°ë˜ë˜ì–´ì•¼ ì°¨ìµê±°ë˜ ê°€ëŠ¥
            if len(symbol_prices) >= 2:
                symbol_prices.sort(key=lambda x: x['price'])
                
                for i in range(len(symbol_prices)):
                    for j in range(i + 1, len(symbol_prices)):
                        buy_data = symbol_prices[i]
                        sell_data = symbol_prices[j]
                        
                        spread_pct = ((sell_data['price'] - buy_data['price']) / buy_data['price']) * 100
                        
                        if spread_pct > 0.5:  # 0.5% ì´ìƒì˜ ì°¨ìµê±°ë˜ ê¸°íšŒ
                            opportunities.append({
                                'symbol': symbol,
                                'buy_exchange': buy_data['exchange'].title(),
                                'sell_exchange': sell_data['exchange'].title(),
                                'buy_price': round(buy_data['price'], 2),
                                'sell_price': round(sell_data['price'], 2),
                                'spread_percentage': round(spread_pct, 2),
                                'confidence': min(95, 80 + spread_pct * 2),  # ì‹ ë¢°ë„ ê³„ì‚°
                                'volume': min(buy_data['volume'], sell_data['volume']),
                                'timestamp': datetime.now().isoformat()
                            })
        
        # ìŠ¤í”„ë ˆë“œ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ ê¸°íšŒë“¤ ë°˜í™˜
        opportunities.sort(key=lambda x: x['spread_percentage'], reverse=True)
        return opportunities[:10]  # ìƒìœ„ 10ê°œ
    
    def calculate_kimchi_premiums(self, exchange_prices: Dict) -> List[Dict]:
        """ê¹€ì¹˜ í”„ë¦¬ë¯¸ì—„ ê³„ì‚° (í•œêµ­ ê±°ë˜ì†Œ vs ê¸€ë¡œë²Œ ê±°ë˜ì†Œ)"""
        premiums = []
        
        korean_exchanges = ['upbit', 'coinone']  # í•œêµ­ ê±°ë˜ì†Œ
        global_exchanges = ['okx', 'gate']       # ê¸€ë¡œë²Œ ê±°ë˜ì†Œ
        
        # ê³µí†µ ì‹¬ë³¼ ì°¾ê¸°
        common_symbols = set()
        for exchange_data in exchange_prices.values():
            if not common_symbols:
                common_symbols = set(exchange_data.keys())
            else:
                common_symbols &= set(exchange_data.keys())
        
        for symbol in common_symbols:
            korean_prices = []
            global_prices = []
            
            # í•œêµ­ ê±°ë˜ì†Œ ê°€ê²© ìˆ˜ì§‘
            for exchange in korean_exchanges:
                if exchange in exchange_prices and symbol in exchange_prices[exchange]:
                    korean_prices.append({
                        'exchange': exchange,
                        'price': exchange_prices[exchange][symbol]['price']
                    })
            
            # ê¸€ë¡œë²Œ ê±°ë˜ì†Œ ê°€ê²© ìˆ˜ì§‘
            for exchange in global_exchanges:
                if exchange in exchange_prices and symbol in exchange_prices[exchange]:
                    global_prices.append({
                        'exchange': exchange,
                        'price': exchange_prices[exchange][symbol]['price']
                    })
            
            if korean_prices and global_prices:
                # í‰ê·  ê°€ê²© ê³„ì‚°
                avg_korean = sum(p['price'] for p in korean_prices) / len(korean_prices)
                avg_global = sum(p['price'] for p in global_prices) / len(global_prices)
                
                premium_pct = ((avg_korean - avg_global) / avg_global) * 100
                
                premiums.append({
                    'symbol': symbol,
                    'korean_exchange': korean_prices[0]['exchange'].title(),
                    'global_exchange': global_prices[0]['exchange'].title(),
                    'korean_price': round(avg_korean, 2),
                    'global_price': round(avg_global, 2),
                    'premium_percentage': round(premium_pct, 2),
                    'status': 'positive' if premium_pct > 0 else 'negative',
                    'timestamp': datetime.now().isoformat()
                })
        
        return premiums
    
    async def broadcast_real_data(self, price_data, arbitrage_data, kimchi_data):
        """ì‹¤ì œ ë°ì´í„°ë¥¼ WebSocketìœ¼ë¡œ ë¸Œë¡œë“œìºìŠ¤íŠ¸"""
        try:
            timestamp = datetime.now().isoformat()
            
            # ê°€ê²© ë°ì´í„° ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await connection_manager.broadcast_to_all({
                'type': 'price_update',
                'data': price_data,
                'timestamp': timestamp,
                'source': 'real_api'
            })
            
            # ì°¨ìµê±°ë˜ ê¸°íšŒ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            if arbitrage_data:
                await connection_manager.broadcast_to_all({
                    'type': 'arbitrage_opportunities',
                    'data': arbitrage_data,
                    'timestamp': timestamp,
                    'source': 'real_api'
                })
            
            # ê¹€ì¹˜ í”„ë¦¬ë¯¸ì—„ ë¸Œë¡œë“œìºìŠ¤íŠ¸
            if kimchi_data:
                await connection_manager.broadcast_to_all({
                    'type': 'kimchi_premium',
                    'data': kimchi_data,
                    'timestamp': timestamp,
                    'source': 'real_api'
                })
            
            self.stats['broadcasts_sent'] += 3
            
            logger.info(f"ğŸ“¡ ì‹¤ì œ ë°ì´í„° ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì™„ë£Œ - "
                       f"ê°€ê²©: {len(price_data)}ê°œ, "
                       f"ì°¨ìµê±°ë˜: {len(arbitrage_data)}ê°œ, "
                       f"ê¹€ì¹˜í”„ë¦¬ë¯¸ì—„: {len(kimchi_data)}ê°œ")
                       
        except Exception as e:
            logger.error(f"âŒ ë°ì´í„° ë¸Œë¡œë“œìºìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    async def start_collection_loop(self):
        """ë°ì´í„° ìˆ˜ì§‘ ë£¨í”„ ì‹œì‘"""
        self.running = True
        self.stats['start_time'] = datetime.now()
        
        logger.info(f"ğŸš€ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ë£¨í”„ ì‹œì‘ (ê°„ê²©: {self.collection_interval}ì´ˆ)")
        
        while self.running:
            try:
                await self.collect_and_broadcast_data()
                
                # í†µê³„ ì¶œë ¥
                uptime = (datetime.now() - self.stats['start_time']).total_seconds()
                logger.info(f"ğŸ“ˆ ì„œë¹„ìŠ¤ ìƒíƒœ - "
                           f"ì—…íƒ€ì„: {uptime/60:.1f}ë¶„, "
                           f"ìˆ˜ì§‘: {self.stats['data_points_collected']}ê°œ, "
                           f"ë¸Œë¡œë“œìºìŠ¤íŠ¸: {self.stats['broadcasts_sent']}íšŒ, "
                           f"ê±°ë˜ì†Œ: {len(self.stats['active_exchanges'])}ê°œ")
                
                await asyncio.sleep(self.collection_interval)
                
            except Exception as e:
                logger.error(f"âŒ ìˆ˜ì§‘ ë£¨í”„ ì˜¤ë¥˜: {e}")
                await asyncio.sleep(10)  # ì˜¤ë¥˜ ì‹œ 10ì´ˆ ëŒ€ê¸°
    
    def stop(self):
        """ì„œë¹„ìŠ¤ ì¤‘ì§€"""
        self.running = False
        logger.info("ğŸ›‘ ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤ ì¤‘ì§€")

# ê¸€ë¡œë²Œ ì¸ìŠ¤í„´ìŠ¤
real_data_service = RealDataService()

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        logger.info("ğŸ¯ ì‹¤ì œ ê±°ë˜ì†Œ ë°ì´í„° ìˆ˜ì§‘ ì„œë¹„ìŠ¤ ì‹œì‘")
        
        # ê±°ë˜ì†Œ ì´ˆê¸°í™”
        await real_data_service.initialize_exchanges()
        
        # ë°ì´í„° ìˆ˜ì§‘ ë£¨í”„ ì‹œì‘
        await real_data_service.start_collection_loop()
        
    except KeyboardInterrupt:
        logger.info("â¹ï¸ ì‚¬ìš©ìì— ì˜í•œ ì„œë¹„ìŠ¤ ì¤‘ì§€")
    except Exception as e:
        logger.error(f"âŒ ì„œë¹„ìŠ¤ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
    finally:
        real_data_service.stop()

if __name__ == "__main__":
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs('logs', exist_ok=True)
    
    # ë¹„ë™ê¸° ì‹¤í–‰
    asyncio.run(main())
